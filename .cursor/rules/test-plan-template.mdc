---
description: Standard structure template for test plans and experimental designs
globs: **/tests/**/*.md,**/experiments/**/*.md
alwaysApply: false
lastReviewed: 2025-11-01
healthScore:
  content: green # Clear structure, 7 required sections, validity guidance
  usability: green # Reduced from 334→~240 lines, condensed examples
  maintenance: green # Deep maintenance 2025-11-01, verbosity reduced
---

# Test Plan Template

Standard structure for test plans, hypothesis tests, and experimental designs.

**Origin**: Pattern detected across 5 test plan documents in rules-enforcement-investigation project.

## Required Sections

### 1. Background

**Purpose**: Provide context for the test

**Include**:

- Current state being tested
- Hypothesis or objective
- Why this test matters (connection to larger goal)
- Any relevant prior findings

**Example**: Current state description, hypothesis statement, relevance to investigation goal.

### 2. Test Design

**Purpose**: Define test methodology

**Include**:

- Control group (baseline conditions)
- Experimental group (with change applied)
- Test scenarios (specific situations to test)
- Measurement approach (what data to collect)

**Phases** (if applicable):

- Phase 1: Baseline
- Phase 2: Implementation
- Phase 3: Testing
- Phase 4: Comparison/Analysis

**Example**: Control group baseline conditions, experimental group changes, test scenarios list, measurement methods.

### 3. Success Criteria

**Purpose**: Define what success looks like (measurable thresholds)

**Include**:

- Primary metrics with targets
- Secondary metrics (if applicable)
- Success thresholds (quantitative)
- Failure conditions

**Format**:

```markdown
### Primary Metrics

**[Metric Name]**:

- Baseline: X%
- Target: >Y%
- Success threshold: Improvement ≥Z percentage points
```

**Example**: Metric name, baseline value, target value, success threshold with quantitative improvement target.

### 4. Measurement Protocol

**Purpose**: Define HOW to collect data and analyze results

**Include**:

- Data collection templates (YAML, CSV, or structured format)
- Analysis method (calculations, comparisons)
- Tools or scripts needed

**Data Template Format**:

```yaml
# or CSV
scenario_id: 1
input: "[test input]"
expected: "[expected result]"
actual: "[actual result]"
success: [yes/no]
notes: "[observations]"
```

**Example**: Data template format (YAML/CSV), fields to capture, analysis calculations.

### 5. Expected Outcomes

**Purpose**: Define scenarios and their interpretations

**Include**:

- Scenario 1-N: Different possible results
- Implications for each scenario
- Next steps based on results
- Decision trees if complex

**Format**:

```markdown
### Scenario 1: [Hypothesis Confirmed]

**Observations**:

- [What we'd see]

**Implications**:

- [What this means]

**Next Steps**:

- [What to do next]
```

**Example**: Scenario name, observations, implications, next steps based on results.

### 6. Implementation Checklist

**Purpose**: Step-by-step execution guide

**Include**:

- Pre-test setup steps
- Test execution steps
- Data collection steps
- Analysis steps
- Post-test cleanup/reporting

**Format**:

```markdown
### Pre-Test Setup

- [ ] Create test environment
- [ ] Backup affected files
- [ ] Document baseline state

### Test Execution

- [ ] Run scenario 1
- [ ] Record data
- [ ] Run scenario 2
      ...
```

**Example**: Pre-test setup, test execution steps, data collection, analysis, cleanup checklist.

### 7. Timeline & Effort

**Purpose**: Resource planning

**Include**:

- Estimated duration for each phase/test
- Total effort estimate
- Risks that might affect timeline

**Example**: Per-phase durations, total effort, timeline risks.

## Optional Sections

- **Risk Mitigation**: For complex tests or rule changes — document risks and mitigation strategies
- **Follow-Up Actions**: When results trigger different paths — define next steps per outcome scenario

## Usage

**When to use this template**:

- Creating hypothesis tests for investigations
- Designing experiments to validate improvements
- Documenting A/B tests or comparisons
- Any structured validation requiring measurement

**How to use**:

1. Copy structure (7 required sections)
2. Fill in each section with test-specific details
3. Add optional sections as needed
4. Ensure measurement protocols are complete
5. Define clear success criteria before executing

## Examples from Rules-Enforcement-Investigation

All test plans in `docs/projects/rules-enforcement-investigation/tests/` follow this structure:

- `hypothesis-1-conditional-attachment.md` — Control vs experimental groups
- `hypothesis-2-send-gate-enforcement.md` — Multi-phase testing (A/B/C/D)
- `hypothesis-3-query-protocol-visibility.md` — Before/after comparison
- `experiment-slash-commands.md` — 4-phase comparative experiment
- `measurement-framework.md` — Tool implementation + validation

## Measurement Validity (AI Assistant Testing)

**Valid**: Historical analysis, natural usage monitoring, user-observed validation, external validation (CI/hooks/linters)

**Invalid**: Prospective self-testing (observer bias — consciousness of testing changes measured behavior)

**See**: `docs/projects/assistant-self-testing-limits/` for detailed measurement strategies and decision frameworks

## Related

- See `rule-creation.mdc` for general rule authoring guidelines
- See `spec-driven.mdc` for specification-driven development patterns
- See `generate-tasks-from-erd.mdc` for task generation from requirements
